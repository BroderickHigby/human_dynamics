<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-10550309-9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10550309-9');
</script>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<link rel="stylesheet" type="text/css" href="style.css" media="screen" />

<html>
  <head>
    <title>Learning 3D Human Dynamics from Video</title>
    <meta property="og:title" content="Human Dynamics" />
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">Learning 3D Human Dynamics from Video</span>
    </center>

    <br><br>
      <table align=center width=800px>
      <tr>
        <td align=center width=100px>
           <span style="font-size:20px"><a href="http://www.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa<sup>*</sup></a></span>
         </td>
        <td align=center width=100px>
          <span style="font-size:20px"><a href="https://jasonyzhang.com">Jason Y. Zhang<sup>*</sup></a></span>
        </td>
        <td align=center width=100px>
          <span style="font-size:20px">Panna Felsen<sup>*</sup></span>
        </td>
        <td align=center width=100px>
          <center>
          <span style="font-size:20px"><a href="http://www.eecs.berkeley.edu/~malik/">Jitendra Malik</a></span>
          </center>
        </td>
     </tr>
     </table>

    <table align=center width=700px>
      <tr>
        <td align=center width=100px>
          <center>
          <span style="font-size:20px">University of California, Berkeley</span>
          </center>
        </td>
      </tr>
    </table>

    <br>
      <table align=center width=400px>
        <tr>
          <td align=center width=100px>
            <span style="font-size:20px; text-align:center;"><a href="https://arxiv.org/abs/1812.01601">[Paper]</a></span>
          </td>
          <td align=center width=100px>
            <center>
            <span style="font-size:20px"><a href="https://www.youtube.com/watch?v=9fNKSZdsAG8">[Video]</a></span>
            </center>
          </td>
        </tr>
      </table>
      <br>
      <br>
      <table align=center width=1000px>
        <tr>
          <td valign="middle" halign="middle">
            <video autoplay loop muted playsinline height="270px">
              <source src="resources/videos/comp_fencing.mp4" type="video/mp4">
            </video>
          </td>
          <td valign="middle" halign="middle">
            <center>
              <img src = "./resources/images/teaser.jpg" height="350px"></img><br>
            </center>
          </td>
        </tr>
        <tr>
          <!-- <td colspan="2"> -->
          <td>
            <center>
            <span style="font-size:14px"><i>
              From a video of a human, our model (blue) can predict 3D meshes that are more temporally consistent
              than a method that only uses a single view (pink).
            </i></span>
            </center>
          </td>
          <td>
            <span style="font-size:14px; text-align:center;"><i>
              From a single image (purple), our model can recovers the current 3D mesh as well as the past
              and future 3D poses.
            </i></span>
          </td>
        </tr>
      </table>
        <br><br>
    From an image of a person in action, we can easily guess the 3D motion of
    the person in the immediate past and future. This is because we have a
    mental model of 3D human dynamics that we have acquired from observing
    visual sequences of humans in motion. We present a framework that can
    similarly learn a representation of 3D dynamics of humans from video via a
    simple but effective temporal encoding of image features. At test time, from
    video, the learned temporal representation give rise to smooth 3D mesh
    predictions. From a single image, our model can recover the current 3D mesh
    as well as its 3D past and future motion. Our approach is designed so it can
    learn from videos with 2D pose annotations in a semi-supervised manner.
    Though annotated data is always limited, there are millions of videos
    uploaded daily on the Internet. In this work, we harvest this Internet-scale
    source of unlabeled data by training our model on unlabeled video with
    pseudo-ground truth 2D pose obtained from an off-the-shelf 2D pose detector.
    Our experiments show that adding more videos with pseudo-ground truth 2D
    pose monotonically improves 3D prediction performance. We evaluate our
    model, Human Mesh and Motion Recovery (HMMR), on the recent challenging
    dataset of 3D Poses in the Wild and obtain state-of-the-art performance on
    the 3D prediction task without any fine-tuning.

      <br><br>
      <hr>
      <table align=center width=800>
       <center><h1>Paper</h1></center>
          <tr>
            <td><a href="https://arxiv.org/abs/1812.01601"><img style="width:400px" src="./resources/images/thumb.jpg"/></a></td>
            <td><span style="font-size:14pt">Kanazawa<sup>*</sup>, Zhang<sup>*</sup>, Felsen<sup>*</sup>, and Malik.<br><br>
                Learning 3D Human Dynamics from Video.<br><br>
              CVPR 2019.<br>
                <a href="https://arxiv.org/pdf/1812.01601.pdf">[pdf]</a> &nbsp; &nbsp;
                <a href="./resources/bibtex.txt">[Bibtex]</a></span><br>
              </td>
          </tr>
      </table>

      <hr>

      <center><h1>Project Video</h1></center>
      <table align=center width=900px>
        <tr>
          <td width=600px>
            <center>
              <div class="video">
                <iframe width="720" height="405" src="https://www.youtube.com/embed/9fNKSZdsAG8" frameborder="0" allowfullscreen></iframe>
              </div>
          </center>
          </td>
          </tr>
      </table>

      <br>
      <hr>
      <h1>Code</h1>
      <table align=center width=1000px>
        <tr style="text-align:center;">
          <center>
            <img class="round" style="width:90%; text-align:center;" src="./resources/images/overview.jpg"/>
          </center>
        </tr>
      </table>

      <table align=center width=800px>
        <tr>
          <center> <br>
            <span style="font-size:28px">&nbsp;<a href='https://github.com/akanazawa/human_dynamics/tree/master'>[GitHub]</a>  </span>
            <span style="font-size:28px"><a></a></span>
            <br>
          </center>
        </tr>
      </table>

      <hr>
      <h2>Demo Results</h2>


    <div>
      <video autoplay loop muted playsinline width="49%">
        <source src="resources/videos/demo_results/insta_variety-tabletennis_43078913_895055920883203_6720141320083472384_n_short.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="49%">
        <source src="resources/videos/demo_results/insta_variety-tabletennis_43078913_895055920883203_6720141320083472384_n_short_1.mp4" type="video/mp4">
      </video>
    </div>

    <div>

      <video autoplay loop muted playsinline width="28%">
        <source src="resources/videos/demo_results/insta_variety-hammerthrow_44692705_761535737521282_2601145950961401856_n.mp4" type="video/mp4">
      </video>

      <video autoplay loop muted playsinline width="35%">
        <source src="resources/videos/demo_results/insta_variety-dunking_45062340_271806740144972_8388967432928100352_n_short.mp4" type="video/mp4">
      </video>

      <video autoplay loop muted playsinline width="35%">
        <source src="resources/videos/demo_results/insta_variety-dunking_45062340_271806740144972_8388967432928100352_n_short_1.mp4" type="video/mp4">
      </video>
    </div>


    <div>
      <video autoplay loop muted playsinline width="49.061%">
        <source src="resources/videos/demo_results/davis-hike.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="48.939%">
        <source src="resources/videos/demo_results/penn_action-2278.mp4" type="video/mp4">
      </video>
    </div>


    <div>
      <video autoplay loop muted playsinline width="37.69%">
        <source src="resources/videos/demo_results/penn_action-0025.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="37.69%">
        <source src="resources/videos/demo_results/penn_action-0191.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="22.615%">
        <source src="resources/videos/demo_results/insta_variety-penaltykick_41547959_335548243685531_1308440788490774406_n.mp4" type="video/mp4">
      </video>
    </div>

    <div>
      <video autoplay loop muted playsinline width="49%">
        <source src="resources/videos/demo_results/davis-running.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="49%">
        <source src="resources/videos/demo_results/davis-running_1.mp4" type="video/mp4">
      </video>
    </div>

    <div>
      <video autoplay loop muted playsinline width="32.6666%">
        <source src="resources/videos/demo_results/insta_variety-hopscotch_43813243_2107404859281597_3742315295469993984_n_short.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="32.6666%">
        <source src="resources/videos/demo_results/insta_variety-javelinthrow_43507032_402312343639705_4410464175189790871_n.mp4" type="video/mp4">
      </video>
      <video autoplay loop muted playsinline width="32.6666%">
        <source src="resources/videos/demo_results/insta_variety-instagolf_43360267_1374021216067656_1767444579209969664_n.mp4" type="video/mp4">
      </video>
    </div>

    <div>
      <video autoplay loop muted playsinline width="56%">
        <source src="resources/videos/demo_results/penn_action-0910.mp4" type="video/mp4">
      </video>

      <video autoplay loop muted playsinline width="42%">
        <source src="resources/videos/demo_results/penn_action-0486.mp4" type="video/mp4">
      </video>
    </div>

      <br>

      <hr>

    <h1>More Results</h1>
      <table align=center width=900px>
        <tr>
          <td width=600px>
              <div class="video">
                <iframe width="720" height="405" src="https://www.youtube.com/embed/9fNKSZdsAG8?start=300" frameborder="0" allowfullscreen></iframe>
              </div>
          </td>
          </tr>
      </table>

    <br>

    <hr>


      <table align=center width=1100px>
        <tr>
          <td>
            <left>
              <center>
                <h1>Acknowledgements</h1>
              </center>
              We thank David Fouhey for providing us with the people subset of
              VLOG, Rishabh Dabral for providing the source code for TP-Net,
              Timo von Marcard and Gerard Pons-Moll for help with
              3DPW, and Heather Lockwood for her help and support.  This work was supported in part by Intel/NSF VEC award
              IIS-1539099 and BAIR sponsors. This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
          </td>
        </tr>
      </table>

      <br><br>
</body>
</html>
